{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV,cross_validate\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer,make_column_selector\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation CSV et création du dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Real_estate</th>\n",
       "      <th>MIS_Status</th>\n",
       "      <th>Portion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IN</td>\n",
       "      <td>Retail trade</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IN</td>\n",
       "      <td>Accommodation and food services</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IN</td>\n",
       "      <td>Health care and social assistance</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OK</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FL</td>\n",
       "      <td>Transportation and warehousing</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896116</th>\n",
       "      <td>OH</td>\n",
       "      <td>Retail trade</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896117</th>\n",
       "      <td>OH</td>\n",
       "      <td>Retail trade</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896118</th>\n",
       "      <td>CA</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896119</th>\n",
       "      <td>HI</td>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896120</th>\n",
       "      <td>HI</td>\n",
       "      <td>Information</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>896121 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       State                           Industry  Real_estate  MIS_Status  \\\n",
       "0         IN                       Retail trade            0           0   \n",
       "1         IN    Accommodation and food services            0           0   \n",
       "2         IN  Health care and social assistance            0           0   \n",
       "3         OK                      Manufacturing            0           0   \n",
       "4         FL     Transportation and warehousing            1           0   \n",
       "...      ...                                ...          ...         ...   \n",
       "896116    OH                       Retail trade            0           0   \n",
       "896117    OH                       Retail trade            0           0   \n",
       "896118    CA                      Manufacturing            0           0   \n",
       "896119    HI                      Manufacturing            0           1   \n",
       "896120    HI                        Information            0           0   \n",
       "\n",
       "        Portion  \n",
       "0          0.80  \n",
       "1          0.80  \n",
       "2          0.75  \n",
       "3          0.80  \n",
       "4          1.00  \n",
       "...         ...  \n",
       "896116     0.80  \n",
       "896117     0.50  \n",
       "896118     0.75  \n",
       "896119     0.80  \n",
       "896120     0.80  \n",
       "\n",
       "[896121 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de la matrice X (variables explicatives) et de la série y (variable cible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8250411493932208"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['MIS_Status','Portion'], axis=1)\n",
    "y = df['MIS_Status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,shuffle=True, train_size=0.8, random_state=42)\n",
    "\n",
    "# Score du dummy classifier\n",
    "dummy = DummyClassifier()\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = make_column_transformer(\n",
    "    (OneHotEncoder(),make_column_selector(dtype_exclude=np.number)),\n",
    "    (StandardScaler(),make_column_selector(dtype_include=np.number))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<716896x71 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2150688 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=make_pipeline(transformer).fit_transform(X_train)\n",
    "a\n",
    "a_columns= transformer.get_feature_names_out()\n",
    "adf= pd.DataFrame(a)#.set_index(y_train.index)\n",
    "# adf.columns = a_columns\n",
    "adf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'un  RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'csr_matrix'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39m# Entrainement de notre modèle en utilisant les paramètres par défaut \u001b[39;00m\n\u001b[1;32m     10\u001b[0m rf\u001b[39m=\u001b[39mRandomForestClassifier()\n\u001b[0;32m---> 11\u001b[0m rf\u001b[39m.\u001b[39;49mfit(adf, y_train)\n\u001b[1;32m     13\u001b[0m \u001b[39m#Utilisation d'un .features_importances_ pour déterminer quelle variable est importante pour la prédiction\u001b[39;00m\n\u001b[1;32m     14\u001b[0m rf\u001b[39m.\u001b[39mfeatures_importances_\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:346\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[1;32m    345\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 346\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    347\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[1;32m    348\u001b[0m )\n\u001b[1;32m    349\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/base.py:554\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    552\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    553\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 554\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    555\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/utils/validation.py:1104\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1100\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1101\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1102\u001b[0m     )\n\u001b[0;32m-> 1104\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1105\u001b[0m     X,\n\u001b[1;32m   1106\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m   1107\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m   1108\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1109\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m   1110\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   1111\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m   1112\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m   1113\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m   1114\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m   1115\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m   1116\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m   1117\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1118\u001b[0m )\n\u001b[1;32m   1120\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[1;32m   1122\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/utils/validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    875\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    876\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 877\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    879\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    881\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/datascience_env/lib/python3.9/site-packages/pandas/core/generic.py:1899\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 1899\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "forest= make_pipeline(\n",
    "    transformer,\n",
    "    RandomForestClassifier(\n",
    "        max_depth=5,\n",
    "        n_estimators=100,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Entrainement de notre modèle en utilisant les paramètres par défaut \n",
    "rf=RandomForestClassifier()\n",
    "rf.fit(adf, y_train)\n",
    "\n",
    "#Utilisation d'un .features_importances_ pour déterminer quelle variable est importante pour la prédiction\n",
    "rf.features_importances_\n",
    "\n",
    "# Score de notre modèle après la cross_validation\n",
    "cross_val=cross_validate(forest, X_train, y_train,scoring='f1',cv=5)\n",
    "cross_val['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création d'une LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo_reg = make_pipeline(\n",
    "    transformer,\n",
    "    LogisticRegression(\n",
    "        penalty='l2',\n",
    "        solver='newton-cholesky',\n",
    "        class_weight='balanced',\n",
    "        multi_class='ovr'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Entrainement de notre modèle en utilisant les paramètres par défaut \n",
    "lo_reg.fit(X_train,y_train)\n",
    "\n",
    "# Score de notre modèle après la cross_validation\n",
    "cross_val=cross_validate(lo_reg, X_train, y_train,scoring='f1',cv=5)\n",
    "cross_val['test_score'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation d'un RandomSearch pour obtenir une idée de l'ordre de grandeur des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('columntransformer',\n",
       "   ColumnTransformer(transformers=[('onehotencoder', OneHotEncoder(),\n",
       "                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3220>),\n",
       "                                   ('standardscaler', StandardScaler(),\n",
       "                                    <sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3f70>)])),\n",
       "  ('logisticregression',\n",
       "   LogisticRegression(class_weight='balanced', multi_class='ovr',\n",
       "                      solver='newton-cholesky'))],\n",
       " 'verbose': False,\n",
       " 'columntransformer': ColumnTransformer(transformers=[('onehotencoder', OneHotEncoder(),\n",
       "                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3220>),\n",
       "                                 ('standardscaler', StandardScaler(),\n",
       "                                  <sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3f70>)]),\n",
       " 'logisticregression': LogisticRegression(class_weight='balanced', multi_class='ovr',\n",
       "                    solver='newton-cholesky'),\n",
       " 'columntransformer__n_jobs': None,\n",
       " 'columntransformer__remainder': 'drop',\n",
       " 'columntransformer__sparse_threshold': 0.3,\n",
       " 'columntransformer__transformer_weights': None,\n",
       " 'columntransformer__transformers': [('onehotencoder',\n",
       "   OneHotEncoder(),\n",
       "   <sklearn.compose._column_transformer.make_column_selector at 0x7f7a7d0e3220>),\n",
       "  ('standardscaler',\n",
       "   StandardScaler(),\n",
       "   <sklearn.compose._column_transformer.make_column_selector at 0x7f7a7d0e3f70>)],\n",
       " 'columntransformer__verbose': False,\n",
       " 'columntransformer__verbose_feature_names_out': True,\n",
       " 'columntransformer__onehotencoder': OneHotEncoder(),\n",
       " 'columntransformer__standardscaler': StandardScaler(),\n",
       " 'columntransformer__onehotencoder__categories': 'auto',\n",
       " 'columntransformer__onehotencoder__drop': None,\n",
       " 'columntransformer__onehotencoder__dtype': numpy.float64,\n",
       " 'columntransformer__onehotencoder__handle_unknown': 'error',\n",
       " 'columntransformer__onehotencoder__max_categories': None,\n",
       " 'columntransformer__onehotencoder__min_frequency': None,\n",
       " 'columntransformer__onehotencoder__sparse': 'deprecated',\n",
       " 'columntransformer__onehotencoder__sparse_output': True,\n",
       " 'columntransformer__standardscaler__copy': True,\n",
       " 'columntransformer__standardscaler__with_mean': True,\n",
       " 'columntransformer__standardscaler__with_std': True,\n",
       " 'logisticregression__C': 1.0,\n",
       " 'logisticregression__class_weight': 'balanced',\n",
       " 'logisticregression__dual': False,\n",
       " 'logisticregression__fit_intercept': True,\n",
       " 'logisticregression__intercept_scaling': 1,\n",
       " 'logisticregression__l1_ratio': None,\n",
       " 'logisticregression__max_iter': 100,\n",
       " 'logisticregression__multi_class': 'ovr',\n",
       " 'logisticregression__n_jobs': None,\n",
       " 'logisticregression__penalty': 'l2',\n",
       " 'logisticregression__random_state': None,\n",
       " 'logisticregression__solver': 'newton-cholesky',\n",
       " 'logisticregression__tol': 0.0001,\n",
       " 'logisticregression__verbose': 0,\n",
       " 'logisticregression__warm_start': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pour trouver le nom des paramètres\n",
    "lo_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:420: ConvergenceWarning: Newton solver did not converge after 2 iterations.\n",
      "  warnings.warn(\n",
      "/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:420: ConvergenceWarning: Newton solver did not converge after 2 iterations.\n",
      "  warnings.warn(\n",
      "/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:420: ConvergenceWarning: Newton solver did not converge after 2 iterations.\n",
      "  warnings.warn(\n",
      "/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:420: ConvergenceWarning: Newton solver did not converge after 2 iterations.\n",
      "  warnings.warn(\n",
      "/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/linear_model/_glm/_newton_solver.py:420: ConvergenceWarning: Newton solver did not converge after 2 iterations.\n",
      "  warnings.warn(\n",
      "/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/pipeline.py\", line 406, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/base.py\", line 570, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'C' parameter of LogisticRegression must be a float in the range (0, inf]. Got 0.0 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/anas/miniconda3/envs/datascience_env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.55108412 0.55119989 0.55108412 0.55108412 0.55108412 0.55108412\n",
      " 0.55119989 0.55119989 0.55108412 0.55108412 0.55119989 0.55119989\n",
      " 0.55108412 0.55119989 0.55108412 0.55077445 0.55108412 0.55119989\n",
      " 0.55108412 0.55119989 0.55108412 0.55108412 0.55108412 0.55119989\n",
      " 0.55108412 0.55119989 0.55119989 0.55108412 0.55108412 0.55096276\n",
      " 0.55119989 0.55119989 0.55108412 0.55119989 0.55108412 0.55119989\n",
      " 0.55119989 0.55119989 0.55119989 0.55108412 0.55108412 0.55108412\n",
      " 0.55108412 0.55108412 0.55119989 0.55108412 0.55108412 0.55108412\n",
      " 0.55108412 0.55108412 0.55108412 0.55119989 0.55108412 0.55119989\n",
      " 0.55119989 0.55119989 0.55108412 0.55119989 0.55119989 0.55119989\n",
      " 0.55108412 0.55108412 0.55108412 0.55108412 0.55096276 0.55119989\n",
      " 0.55119989 0.55108412 0.55108412 0.55119989 0.55108412 0.55108412\n",
      " 0.55108412 0.55108412 0.55108412 0.55108412 0.55119989 0.55108412\n",
      " 0.55108412 0.55108412 0.55108412 0.55108412 0.55108412 0.55108412\n",
      " 0.55108412 0.55119989        nan 0.55108412 0.55119989 0.55108412\n",
      " 0.55119989 0.55119989 0.55108412 0.55108412 0.55108412 0.55108412\n",
      " 0.55120966 0.55108412 0.55119989 0.55108412]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logisticregression__max_iter': 176, 'logisticregression__C': 0.15151515151515152}\n"
     ]
    }
   ],
   "source": [
    "param_rand = {'logisticregression__C':np.linspace(0,5,100),\n",
    "              'logisticregression__max_iter':np.arange(0,201,2),\n",
    "                }\n",
    "                \n",
    "random_search = RandomizedSearchCV(lo_reg, param_distributions=param_rand, n_iter=100, cv=5, random_state=42)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisation d'un GridSearch pour cibler les meilleurs paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;onehotencoder&#x27;,\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3220&gt;),\n",
       "                                                                        (&#x27;standardscaler&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3f70&gt;)])),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                           multi_class=&#x27;ovr&#x27;,\n",
       "                                                           solver=&#x27;newton-cholesky&#x27;))]),\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.05],\n",
       "                         &#x27;logisticregression__max_iter&#x27;: array([170, 171, 172, 173, 174, 175, 176, 177, 178, 179])},\n",
       "             scoring=&#x27;f1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;onehotencoder&#x27;,\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3220&gt;),\n",
       "                                                                        (&#x27;standardscaler&#x27;,\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3f70&gt;)])),\n",
       "                                       (&#x27;logisticregression&#x27;,\n",
       "                                        LogisticRegression(class_weight=&#x27;balanced&#x27;,\n",
       "                                                           multi_class=&#x27;ovr&#x27;,\n",
       "                                                           solver=&#x27;newton-cholesky&#x27;))]),\n",
       "             param_grid={&#x27;logisticregression__C&#x27;: [0.05],\n",
       "                         &#x27;logisticregression__max_iter&#x27;: array([170, 171, 172, 173, 174, 175, 176, 177, 178, 179])},\n",
       "             scoring=&#x27;f1&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehotencoder&#x27;,\n",
       "                                                  OneHotEncoder(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3220&gt;),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3f70&gt;)])),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(class_weight=&#x27;balanced&#x27;, multi_class=&#x27;ovr&#x27;,\n",
       "                                    solver=&#x27;newton-cholesky&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">columntransformer: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;onehotencoder&#x27;, OneHotEncoder(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3220&gt;),\n",
       "                                (&#x27;standardscaler&#x27;, StandardScaler(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3f70&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehotencoder</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3220&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">standardscaler</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3f70&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, multi_class=&#x27;ovr&#x27;,\n",
       "                   solver=&#x27;newton-cholesky&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('onehotencoder',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3220>),\n",
       "                                                                        ('standardscaler',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         <sklearn.compose._column_transformer.make_column_selector object at 0x7f7a7d0e3f70>)])),\n",
       "                                       ('logisticregression',\n",
       "                                        LogisticRegression(class_weight='balanced',\n",
       "                                                           multi_class='ovr',\n",
       "                                                           solver='newton-cholesky'))]),\n",
       "             param_grid={'logisticregression__C': [0.05],\n",
       "                         'logisticregression__max_iter': array([170, 171, 172, 173, 174, 175, 176, 177, 178, 179])},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'logisticregression__C':[0.05],\n",
    "          'logisticregression__max_iter':np.arange(170,180,1),\n",
    "            }\n",
    "\n",
    "grid=GridSearchCV(lo_reg, param_grid=params, scoring='f1', cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37606272607064106"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Jun  1 2022, 11:38:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e48bd86671c665102a0c6a972f64dec55f72ec0b4a13e9063e0389fef656118c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
